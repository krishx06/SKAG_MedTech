# .env.example
# AdaptiveCare Backend Environment Variables
# Copy this to .env and fill in your values

# ============================================
# REQUIRED
# ============================================

# Python path (set to your project root)
PYTHONPATH=/absolute/path/to/SKAG_MedTech

# ============================================
# OPTIONAL - API Keys
# ============================================

# Google Gemini API (for LLM reasoning)
# Get key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# ============================================
# SERVER CONFIGURATION
# ============================================

# Debug mode (false for production)
DEBUG=false

# Server host and port
HOST=0.0.0.0
PORT=8000

# ============================================
# CORS (Frontend URLs)
# ============================================

# Comma-separated list of allowed origins
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]

# For production, add your deployed frontend:
# CORS_ORIGINS=["https://yourfrontend.com","http://localhost:5173"]

# ============================================
# DATABASE
# ============================================

# SQLite (default - no configuration needed)
DATABASE_URL=sqlite:///./adaptivecare.db

# PostgreSQL (production)
# DATABASE_URL=postgresql://user:password@host:5432/adaptivecare

# ============================================
# AGENT CONFIGURATION
# ============================================

# MCDA Weights (decision making)
RISK_WEIGHT=0.4
CAPACITY_WEIGHT=0.3
WAIT_TIME_WEIGHT=0.2
RESOURCE_WEIGHT=0.1

# Decision Thresholds
ESCALATE_THRESHOLD=0.75
HIGH_RISK_THRESHOLD=70.0
CRITICAL_RISK_THRESHOLD=85.0

# ============================================
# LLM CONFIGURATION
# ============================================

LLM_MODEL=gemini-1.5-flash
LLM_MAX_TOKENS=500
LLM_TEMPERATURE=0.3
